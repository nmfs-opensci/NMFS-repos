---
title: "Create gitdata for NMFS GitHub ecosystem"
format: html
---

```{r include=FALSE}
library(dplyr)
knitr::opts_chunk$set(eval = FALSE)
```

```{r}
url <- "https://api.github.com/rate_limit"
res <- httr::GET(url,
                 httr::add_headers(Authorization = "token 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"))
res
```

```{r}
non.ent.orgs <- c("noaa-fisheries-integrated-toolbox", "nmfs-fish-tools", "noaa-fims",
          "noaa-iea", "ecosystem-state", "futureseas",
          "pfmc-assessments", "pacific-hake", "nmfs-stock-synthesis", "r4ss", "ss3sim",
          "nwfsc-math-bio", "nwfsc-fram", "NOAA-FEAT", "nwfsc-cb", "NWFSC-OA-lab", "TIDE-NWFSC",
          "rverse-tutorials", "nmfs-opensci",
          "NOAA-EDAB", "PIFSCstockassessments",
          "afsc-assessments", "NMML", "afsc-gap-products", "afsc-ecofoci", "alaska-groundfish-efh",
          "us-amlr", "noaa-garfo"
          )
ent.orgs <- c("NEFSC", "SEFSC", "SWFSC", "PIFSC-NMFS-NOAA")
```

Make a fine grained PAT.

https://api.github.com/orgs/ORG/repos

```{r}
# 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
library(dplyr)
orgtabs <- list()
for(tab_type in c("non.ent.orgs", "ent.orgs")){
  orgnames <- get(tab_type)
  tbl <- list()
  update_tbl <- FALSE
for(org in orgnames[which(!(orgnames %in% names(tbl)))]){
    update_tbl <- TRUE
url <- paste0("https://api.github.com/orgs/", org, "/repos?per_page=100")
res <- httr::GET(url,
                 httr::add_headers(authorization = "token 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"))
dat <- jsonlite::fromJSON(rawToChar(res$content))
dat$org <- org
dat$license_name = ifelse(inherits(dat$license, "logical"), NA, select(dat$license, "spdx_id")$spdx_id)[1]
tbl[[org]] <- dat
cat(org, " ")
}
if(update_tbl) orgtabs[[tab_type]] <- tbl
}
```


```{r}
# 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
library(dplyr)
orgtabs <- list()
for(tab_type in c("non.ent.orgs", "ent.orgs")){
  orgnames <- get(tab_type)
  tbl <- list()
  update_tbl <- FALSE
for(org in orgnames[which(!(orgnames %in% names(tbl)))]){
    update_tbl <- TRUE
url <- paste0("https://api.github.com/search/repositories?q=org:", org)
res <- httr::GET(url,
                 httr::add_headers(authorization = "token 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"))
dat <- jsonlite::fromJSON(rawToChar(res$content))$items
dat$org <- org
dat$license_name = ifelse(inherits(dat$license, "logical"), NA, select(dat$license, "spdx_id")$spdx_id)[1]
tbl[[org]] <- dat
}
if(update_tbl) orgtabs[[tab_type]] <- tbl
}
```

```{r}
tmptbl <- list()
tmptbl[["non-Enterprise GH org"]] <- bind_rows(orgtabs[[1]], .id = "GH_org") %>% 
  mutate(last_update = as.Date(pushed_at, "%Y-%m-%d"),
         topic = ifelse(is.null(unlist(topics)), "", unlist(topics))) %>%
  select(c("GH_org", "name", "language", "last_update", "license_name", "description", "topic"))
tmptbl[["Enterprise GH org"]] <- bind_rows(orgtabs[[2]], .id = "GH_org") %>% 
  mutate(last_update = as.Date(pushed_at, "%Y-%m-%d"),
         topic = ifelse(is.null(unlist(topics)), "", unlist(topics))) %>%
  select(c("GH_org", "name", "language", "last_update", "license_name", "description", "topic"))
org.df <- bind_rows(tmptbl, .id="type")
```

```{r}
nrepos_by_org <- org.df %>% group_by(type, GH_org) %>% 
  summarize(nrepos = length(name),
            updated_2023_2022 = sum(lubridate::year(last_update) %in% c("2023", "2022"), na.rm=TRUE),
            updated_2021_2020 = sum(lubridate::year(last_update) %in% c("2021", "2020"), na.rm=TRUE)) %>%
  arrange(desc(updated_2023_2022))
```

```{r}
nrepos_by_type <- org.df %>% group_by(type) %>% 
  summarize(n = length(unique(GH_org)),
            nrepos = length(name),
            updated_2023_2022 = sum(lubridate::year(last_update) %in% c("2023", "2022"), na.rm=TRUE),
            updated_2021_2020 = sum(lubridate::year(last_update) %in% c("2021", "2020"), na.rm=TRUE)) %>%
  arrange(desc(updated_2023_2022))
```

```{r}
userdat <- read.csv("usernames_nmfs_rug.csv")
usernames_rug <- userdat$GitHub.username[userdat$GitHub.username != ""]
userdat <- read.csv("usernames_other_noaa.csv")
usernames_noaa <- c(usernames_rug, userdat$username[userdat$username != ""])
usernames_noaa <- stringr::str_trim(usernames_noaa)
```

```{r}
#https://api.github.com/repos/NOAA-FIMS/FIMS/contributors
# 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
library(dplyr)
#  tbl <- list()
for(org in unique(org.df$GH_org)[!(unique(org.df$GH_org) %in% names(tbl))]){
  df <- org.df %>% subset(GH_org == org)
  df.repo <- NULL
  for(reponame in df$name){
url <- paste0("https://api.github.com/repos/", org, "/", reponame, "/contributors")
res <- httr::GET(url,
                 httr::add_headers(authorization = "token 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"))
if(rawToChar(res$content)=="") next
dat <- jsonlite::fromJSON(rawToChar(res$content))
if(length(dat) == 0) next
dat$org <- org
dat$repo <- reponame
df.repo <- rbind(df.repo, dat)
  }
  tbl[[org]] <- df.repo
  cat(org, "\n")
}
contributortabs <- tbl
```

```{r}
df.contributors <- bind_rows(contributortabs)  %>% 
  group_by(login) %>% 
  summarize(nrepos = length(login),
            norgs = length(org),
            ncontrib = sum(contributions, na.rm=TRUE))
usernames_orgs <- df.contributors$login[!(df.contributors$login %in% usernames)]
```

```{r}
usernames_all <- c(usernames_noaa, usernames_orgs)
usernames_all <- unique(usernames_all)

usernames_noaa <- c(usernames_noaa, 
                    usernames_all[stringr::str_detect(usernames_all, "NOAA") |   
                                  stringr::str_detect(usernames_all, "noaa") |
                                  stringr::str_detect(usernames_all, "Noaa")])
tmp <- bind_rows(usertabs)
usernames_noaa <- c(usernames_noaa, tmp$login[stringr::str_detect(tmp$email, "noaa") & !is.na(tmp$email)])
for(i in c("NOAA", "NMFS", "NEFSC", "PIFSC", "SWFSC", "SEFSC", "GARFO", "AFSC")){
usernames_noaa <- c(usernames_noaa, tmp$login[stringr::str_detect(tmp$company, i) & !is.na(tmp$company)])
usernames_noaa <- c(usernames_noaa, tmp$login[stringr::str_detect(tmp$bio, i) & !is.na(tmp$bio)])
}
usernames_noaa <- c(usernames_noaa, usernames_rug)
usernames_noaa <- unique(usernames_noaa)

usernames_not_noaa <- read.csv("usernames_not_noaa.csv")$username

# sort(usernames_all[!(usernames_all %in% usernames_noaa) & !(usernames_all %in% usernames_not_noaa)])
```

```{r}
# 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
library(dplyr)
tbl <- list()
#tbl <- userrepotabs
for(username in usernames_noaa[which(!(usernames_noaa %in% names(tbl)))]){
  dat <- NULL
  if(is.null(usertabs[[username]]$public_repos)) next
  for(i in 1:(1+floor(usertabs[[username]]$public_repos/100))){
url <- paste0("https://api.github.com/users/", username, "/repos?per_page=100&page=i")
res <- httr::GET(url,
                 httr::add_headers(authorization = "token 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"))
dat <- bind_rows(dat, jsonlite::fromJSON(rawToChar(res$content)))
}
tbl[[username]] <- dat
cat(username, " ")
}
userrepotabs <- tbl
```

```{r}
# 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
library(dplyr)
# tbl <- list()
# tbl <- usertabs
for(username in usernames_all[which(!(usernames_all %in% names(tbl)))]){
url <- paste0("https://api.github.com/users/", username)
res <- httr::GET(url,
                 httr::add_headers(authorization = "token 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"))
dat <- jsonlite::fromJSON(rawToChar(res$content))
tbl[[username]] <- dat
cat(username, "\n")
}
usertabs <- tbl
```

```{r}
save(non.ent.orgs, ent.orgs, usertabs, orgtabs, contributortabs, userrepotabs, usernames_noaa, usernames_all, file="gitdata.rda")
```
